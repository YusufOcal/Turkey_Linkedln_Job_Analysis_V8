import pandas as pd
import numpy as np
import re
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

print("ğŸ” JOBAPPLICANTINSIGHTS/ENTITYURN ANALYSIS")
print("="*60)

# Load the dataset
df = pd.read_csv('linkedin_jobs_with_combined_functions.csv')

target_column = 'jobApplicantInsights/entityUrn'

print("1. SÃœTUN TEMSÄ°L ANALÄ°ZÄ°")
print("-"*40)
print("Bu sÃ¼tun LinkedIn'in iÅŸ baÅŸvuru insights sisteminin entity URN'lerini temsil ediyor.")
print("URN (Uniform Resource Name): LinkedIn'in internal tracking identifier'Ä±")
print("Muhtemel amaÃ§lar:")
print("  - BaÅŸvuru istatistikleri tracking")
print("  - Ä°ÅŸ ilanÄ±nÄ±n baÅŸvuru performans metrikleri")
print("  - LinkedIn'in internal analytics sistemi")
print("  - BaÅŸvuran profil kategorilerinin analizi")

print(f"\n2. TEMEL VERÄ° YAPISI ANALÄ°ZÄ°")
print("-"*40)

if target_column not in df.columns:
    print(f"âŒ '{target_column}' sÃ¼tunu bulunamadÄ±!")
    print("Mevcut benzer sÃ¼tunlar:")
    similar_cols = [col for col in df.columns if 'applicant' in col.lower() or 'insight' in col.lower() or 'urn' in col.lower()]
    for col in similar_cols:
        print(f"  - {col}")
    exit()

print(f"ğŸ“Š Temel istatistikler:")
print(f"   Veri tipi: {df[target_column].dtype}")
print(f"   Toplam kayÄ±t: {len(df[target_column])}")
print(f"   BoÅŸ olmayan: {df[target_column].notna().sum()}")
print(f"   BoÅŸ olan: {df[target_column].isna().sum()}")
print(f"   BoÅŸ yÃ¼zdesi: {(df[target_column].isna().sum() / len(df[target_column]) * 100):.2f}%")
print(f"   Unique deÄŸer sayÄ±sÄ±: {df[target_column].nunique()}")

# Sample values
print(f"\nğŸ“‹ Ã–rnek deÄŸerler:")
non_null_values = df[target_column].dropna().head(10)
for i, value in enumerate(non_null_values, 1):
    print(f"   {i:2d}. {value}")

print(f"\n3. VERÄ° TÄ°PÄ° UYUMLULUK ANALÄ°ZÄ°")
print("-"*40)

non_null_data = df[target_column].dropna()
print(f"BoÅŸ olmayan veri sayÄ±sÄ±: {len(non_null_data)}")

if len(non_null_data) > 0:
    # Check data type consistency
    all_strings = all(isinstance(x, str) for x in non_null_data)
    print(f"TÃ¼m deÄŸerler string mi: {all_strings}")
    
    # Check for URN pattern
    urn_pattern = r'^urn:li:[a-zA-Z]+:[a-zA-Z0-9\-_]+'
    valid_urns = 0
    invalid_urns = []
    
    for value in non_null_data:
        if isinstance(value, str):
            if re.match(urn_pattern, value):
                valid_urns += 1
            else:
                invalid_urns.append(value)
    
    print(f"\nURN Format Analizi:")
    print(f"   GeÃ§erli URN formatÄ±: {valid_urns}")
    print(f"   GeÃ§ersiz format: {len(invalid_urns)}")
    print(f"   Format uyumluluk: {(valid_urns / len(non_null_data) * 100):.2f}%")
    
    if invalid_urns and len(invalid_urns) <= 10:
        print(f"   GeÃ§ersiz format Ã¶rnekleri: {invalid_urns[:5]}")

print(f"\n4. URN YAPISAL ANALÄ°ZÄ°")
print("-"*40)

if len(non_null_data) > 0:
    # Parse URN structure
    urn_components = []
    urn_types = []
    
    for value in non_null_data:
        if isinstance(value, str) and value.startswith('urn:li:'):
            parts = value.split(':')
            if len(parts) >= 3:
                urn_type = parts[2] if len(parts) > 2 else 'unknown'
                urn_types.append(urn_type)
                urn_components.append({
                    'full_urn': value,
                    'type': urn_type,
                    'id': ':'.join(parts[3:]) if len(parts) > 3 else ''
                })
    
    type_counter = Counter(urn_types)
    print(f"URN Type DaÄŸÄ±lÄ±mÄ±:")
    for urn_type, count in type_counter.most_common(10):
        percentage = (count / len(urn_types)) * 100
        print(f"   {urn_type}: {count} ({percentage:.1f}%)")
    
    # Length analysis
    if urn_components:
        lengths = [len(comp['full_urn']) for comp in urn_components]
        print(f"\nURN Uzunluk Analizi:")
        print(f"   Minimum uzunluk: {min(lengths)}")
        print(f"   Maximum uzunluk: {max(lengths)}")
        print(f"   Ortalama uzunluk: {np.mean(lengths):.1f}")

print(f"\n5. VERÄ° TUTARLILIÄI VE PATTERN ANALÄ°ZÄ°")
print("-"*40)

# Check for duplicates
duplicate_count = df[target_column].duplicated().sum()
unique_ratio = df[target_column].nunique() / df[target_column].notna().sum() * 100

print(f"Veri TutarlÄ±lÄ±ÄŸÄ±:")
print(f"   Tekrar eden deÄŸer: {duplicate_count}")
print(f"   Unique oranÄ±: {unique_ratio:.2f}%")

if duplicate_count > 0:
    print(f"   âš ï¸ Duplicate deÄŸerler tespit edildi!")
    duplicated_values = df[df[target_column].duplicated()][target_column].value_counts().head(5)
    print(f"   En Ã§ok tekrarlanan deÄŸerler:")
    for value, count in duplicated_values.items():
        print(f"      '{value}': {count} kez")

# Pattern consistency
print(f"\nPattern TutarlÄ±lÄ±ÄŸÄ±:")
if len(non_null_data) > 0:
    # Check for different patterns
    patterns = {}
    for value in non_null_data.head(100):  # Sample first 100
        if isinstance(value, str):
            pattern = re.sub(r'[a-zA-Z0-9\-_]+', 'X', value)
            patterns[pattern] = patterns.get(pattern, 0) + 1
    
    print(f"   Tespit edilen pattern sayÄ±sÄ±: {len(patterns)}")
    for pattern, count in Counter(patterns).most_common(5):
        print(f"      '{pattern}': {count} kez")

print(f"\n6. BOÅ VERÄ° ANALÄ°ZÄ° VE Ã–NERÄ°LER")
print("-"*40)

null_percentage = (df[target_column].isna().sum() / len(df[target_column]) * 100)
print(f"BoÅŸ veri oranÄ±: {null_percentage:.2f}%")

if null_percentage > 50:
    print("âš ï¸ YÃœKSEK BOÅ VERÄ° ORANI!")
    print("ğŸ“‹ Ã–neriler:")
    print("   - Bu sÃ¼tun opsiyonel olabilir (analytics feature)")
    print("   - 'NOT_AVAILABLE' deÄŸeri ile doldur")
    print("   - SÃ¼tunu sil (business value dÃ¼ÅŸÃ¼kse)")
    print("   - Job ID'den generate edilebilir mi kontrol et")
elif null_percentage > 20:
    print("âš¡ ORTA BOÅ VERÄ° ORANI")
    print("ğŸ“‹ Ã–neriler:")
    print("   - Pattern-based generation")
    print("   - Job ID + timestamp kombinasyonu")
    print("   - Default URN structure oluÅŸtur")
else:
    print("âœ… DÃœÅÃœK BOÅ VERÄ° ORANI - Kabul edilebilir")

print(f"\n7. BENZER SÃœTUNLAR Ä°LE KARÅILAÅTIRMA")
print("-"*40)

# Find similar columns
similar_columns = []
for col in df.columns:
    if col != target_column:
        if ('urn' in col.lower() or 
            'entity' in col.lower() or 
            'id' in col.lower() or
            'insight' in col.lower() or
            'applicant' in col.lower()):
            similar_columns.append(col)

print(f"Benzer amaca hizmet edebilecek sÃ¼tunlar:")
for col in similar_columns:
    print(f"   - {col}")
    if col in df.columns:
        similarity_check = False
        try:
            # Check for overlapping non-null values
            col_data = df[col].dropna()
            target_data = df[target_column].dropna()
            
            if len(col_data) > 0 and len(target_data) > 0:
                # Check if both are string type
                if (col_data.dtype == 'object' and target_data.dtype == 'object'):
                    common_count = len(set(col_data.astype(str)) & set(target_data.astype(str)))
                    if common_count > 0:
                        print(f"      âš ï¸ {common_count} ortak deÄŸer tespit edildi!")
                        similarity_check = True
                
                print(f"      Unique deÄŸer sayÄ±sÄ±: {df[col].nunique()}")
                print(f"      BoÅŸ veri oranÄ±: {(df[col].isna().sum()/len(df)*100):.1f}%")
        except:
            print(f"      KarÅŸÄ±laÅŸtÄ±rma hatasÄ±")

print(f"\n8. STANDARTLAÅTIRMA Ã–NERÄ°LERÄ°")
print("-"*40)

# Case sensitivity and format issues
if len(non_null_data) > 0:
    # Check for case variations in URN structure
    case_issues = []
    format_issues = []
    
    for value in non_null_data.head(50):  # Sample check
        if isinstance(value, str):
            if not value.startswith('urn:li:'):
                format_issues.append(value)
            if value != value.lower() and 'urn:li:' in value.lower():
                case_issues.append(value)
    
    print(f"Format Standardizasyon:")
    print(f"   Case sensitivity sorunlarÄ±: {len(case_issues)}")
    print(f"   Format sorunlarÄ±: {len(format_issues)}")
    
    if case_issues:
        print(f"   Case sorunlarÄ± Ã¶rnekleri: {case_issues[:3]}")
    if format_issues:
        print(f"   Format sorunlarÄ± Ã¶rnekleri: {format_issues[:3]}")
    
    if not case_issues and not format_issues:
        print("   âœ… Format tutarlÄ±")

print(f"\n9. BUSINESS VALUE VE TRANSFORMATÄ±ON Ã–NERÄ°LERÄ°")
print("-"*40)

print("ğŸ’¼ Business Value Analizi:")
print(f"   - URN'ler LinkedIn'in internal tracking sistemi")
print(f"   - BaÅŸvuru insights'larÄ± iÃ§in kullanÄ±lÄ±yor olabilir")
print(f"   - Analytics ve reporting iÃ§in deÄŸerli")

print(f"\nğŸ”„ Transformation Ã–nerileri:")

if null_percentage > 50:
    print("   1. SÃœTUN SÄ°LME Ã–NERÄ°SÄ°:")
    print("      - %50+ boÅŸ veri business value'yu dÃ¼ÅŸÃ¼rÃ¼yor")
    print("      - Internal tracking iÃ§in gerekli olmayabilir")
    print("      - Analiz iÃ§in kritik deÄŸil")
elif unique_ratio < 50:
    print("   1. VERÄ° KALÄ°TESÄ° GELÄ°ÅTÄ°RME:")
    print("      - Duplicate deÄŸerleri temizle")
    print("      - Unique constraint ekle")
    print("      - Data validation rules")
else:
    print("   1. VERÄ° STANDARDIZASYONU:")
    print("      - Format validation")
    print("      - Case normalization")
    print("      - URN structure validation")

print(f"\n2. ALTERNATÄ°F YAKLAÅIMLAR:")
print("   - Entity type'a gÃ¶re kategorize et")
print("   - URN'den metadata Ã§Ä±kar")
print("   - BaÅŸvuru tracking iÃ§in kullan")
print("   - Analytics dashboard entegrasyonu")

print(f"\n10. KRÄ°TÄ°K Ã–NERÄ°LER VE SONRAKÄ° ADIMLAR")
print("-"*40)

print("ğŸš¨ KRÄ°TÄ°K BULGULAR:")

if null_percentage > 70:
    print("   âš ï¸ YÃœKSEK BOÅ VERÄ° - SÃ¼tunu silmeyi dÃ¼ÅŸÃ¼n!")
elif duplicate_count > len(non_null_data) * 0.1:
    print("   âš ï¸ YÃœKSEK DUPLICATE - Data integrity problemi!")
elif unique_ratio < 30:
    print("   âš ï¸ DÃœÅÃœK UNIQUE ORAN - Veri kalitesi sorunu!")

if len(similar_columns) > 3:
    print("   âš ï¸ Ã‡OK FAZLA BENZER SÃœTUN - Redundancy riski!")

print(f"\nğŸ¯ SONRAKÄ° ADIM Ã–NERÄ°LERÄ°:")
print("   1. URN pattern validation implement et")
print("   2. Null values iÃ§in default generation strategy")
print("   3. Duplicate cleaning procedure")
print("   4. Business stakeholder'larla value confirmation")
print("   5. Performance impact analizi")

print(f"\n" + "="*60)
print("ANALYSIS COMPLETED!")

# Summary stats
print(f"\nğŸ“Š Ã–ZET:")
print(f"   Veri kalitesi: {'DÃœÅÃœK' if null_percentage > 50 else 'ORTA' if null_percentage > 20 else 'YÃœKSEK'}")
print(f"   Business value: {'DÃœÅÃœK' if null_percentage > 70 else 'ORTA' if duplicate_count > 100 else 'YÃœKSEK'}")
print(f"   Transformation Ã¶nceliÄŸi: {'YÃœKSEK' if null_percentage > 50 or duplicate_count > 100 else 'ORTA'}") 