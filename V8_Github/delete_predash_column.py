#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LinkedIn Jobs Dataset - preDashFollowingInfoUrn Column Deletion
company/followingState/preDashFollowingInfoUrn sÃ¼tununu siler ve sonuÃ§larÄ± raporlar
"""

import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

def delete_predash_following_info_urn():
    """preDashFollowingInfoUrn sÃ¼tununu siler ve sonuÃ§larÄ± raporlar"""
    
    print("ğŸ—‘ï¸ LinkedIn Jobs Dataset - preDashFollowingInfoUrn Deletion Operation")
    print("=" * 70)
    
    try:
        # Dataset'i yÃ¼kle
        print("ğŸ“‚ Cleaned dataset yÃ¼kleniyor...")
        df = pd.read_csv('linkedin_jobs_dataset_cleaned_columns.csv')
        
        # Ä°lk durum
        initial_rows = len(df)
        initial_cols = len(df.columns)
        initial_memory = df.memory_usage(deep=True).sum() / 1024**2
        
        print(f"âœ… Dataset yÃ¼klendi!")
        print(f"ğŸ“Š Ä°lk durum: {initial_rows:,} satÄ±r Ã— {initial_cols} sÃ¼tun")
        print(f"ğŸ’¾ Ä°lk memory: {initial_memory:.2f} MB")
        print()
        
        # Silinecek sÃ¼tun
        column_to_delete = 'company/followingState/preDashFollowingInfoUrn'
        
        print("ğŸ¯ DELETION ANALYSIS")
        print("-" * 25)
        
        if column_to_delete in df.columns:
            # Bu sÃ¼tunun detay analizi
            col_data = df[column_to_delete]
            col_memory = col_data.memory_usage(deep=True) / 1024**2
            null_count = col_data.isnull().sum()
            null_pct = (null_count / len(df)) * 100
            unique_count = len(col_data.dropna().unique()) if col_data.notna().sum() > 0 else 0
            
            print(f"ğŸ” {column_to_delete}:")
            print(f"   ğŸ“Š Null: {null_count:,} ({null_pct:.1f}%)")
            print(f"   ğŸ¯ Benzersiz deÄŸer: {unique_count:,}")
            print(f"   ğŸ’¾ Memory: {col_memory:.2f} MB")
            print(f"   ğŸ”— URN format: LinkedIn internal identifier")
            print(f"   âœ… SÄ°LÄ°NECEK!")
            print()
            
            # Silme gerekÃ§esi analizi
            print("ğŸ’¡ DELETION RATIONALE")
            print("-" * 20)
            print("ğŸ“‹ Silme gerekÃ§eleri:")
            print("   1. ğŸ”— Internal URN identifier - limited business value")
            print("   2. ğŸ“Š Following relationship already tracked by other columns")
            print("   3. ğŸ’¾ Memory optimization opportunity")
            print("   4. ğŸ”§ Complex format requires preprocessing")
            print("   5. ğŸ“ˆ Alternative: company/followingState/following (boolean) more useful")
            print()
            
            # FollowingState namespace temizliÄŸi
            following_state_cols = [col for col in df.columns if 'followingState' in col]
            print("ğŸ” FollowingState Namespace Analysis:")
            print(f"   ğŸ“Š Namespace'de kalan sÃ¼tunlar: {len(following_state_cols)-1}")
            for col in following_state_cols:
                if col != column_to_delete:
                    non_null = df[col].notna().sum()
                    print(f"      âœ… {col}: {non_null:,} non-null ({df[col].dtype})")
            print()
        
        # SÃ¼tunu sil
        print("ğŸ—‘ï¸ DELETION PROCESS")
        print("-" * 20)
        
        if column_to_delete in df.columns:
            df_cleaned = df.drop(columns=[column_to_delete])
            
            # Son durum
            final_rows = len(df_cleaned)
            final_cols = len(df_cleaned.columns)
            final_memory = df_cleaned.memory_usage(deep=True).sum() / 1024**2
            
            # Ä°statistikler
            memory_saved = initial_memory - final_memory
            memory_saved_pct = (memory_saved / initial_memory) * 100
            
            print(f"âœ… 1 sÃ¼tun baÅŸarÄ±yla silindi!")
            print(f"ğŸ“Š Son durum: {final_rows:,} satÄ±r Ã— {final_cols} sÃ¼tun")
            print(f"ğŸ’¾ Son memory: {final_memory:.2f} MB")
            print()
            
            print("ğŸ“ˆ OPTIMIZATION RESULTS")
            print("-" * 25)
            print(f"ğŸ”» SÃ¼tun azalmasÄ±: {initial_cols} â†’ {final_cols} (-1)")
            print(f"ğŸ’¾ Memory tasarrufu: {memory_saved:.2f} MB ({memory_saved_pct:.1f}%)")
            print(f"ğŸ“Š SatÄ±r korunma: {final_rows:,} / {initial_rows:,} (100.0%)")
            print()
            
            # Namespace temizlik sonucu
            remaining_following_cols = [col for col in df_cleaned.columns if 'followingState' in col]
            print("ğŸ” NAMESPACE CLEANUP RESULT")
            print("-" * 30)
            print(f"ğŸ“Š FollowingState kalan sÃ¼tunlar: {len(remaining_following_cols)}")
            for col in remaining_following_cols:
                col_type = df_cleaned[col].dtype
                non_null = df_cleaned[col].notna().sum()
                print(f"   âœ… {col}: {non_null:,} non-null ({col_type})")
            print()
            
            # Yeni dosyayÄ± kaydet
            print("ğŸ’¾ SAVING OPTIMIZED DATASET")
            print("-" * 25)
            
            output_filename = 'linkedin_jobs_dataset_optimized_step2.csv'
            df_cleaned.to_csv(output_filename, index=False)
            
            # Dosya boyutu kontrolÃ¼
            file_size = Path(output_filename).stat().st_size / 1024**2
            original_size = Path('linkedin_jobs_dataset_cleaned_columns.csv').stat().st_size / 1024**2
            size_reduction = original_size - file_size
            size_reduction_pct = (size_reduction / original_size) * 100
            
            print(f"âœ… Optimized dataset kaydedildi: {output_filename}")
            print(f"ğŸ“„ Dosya boyutu: {file_size:.1f} MB (Ã¶nceki: {original_size:.1f} MB)")
            print(f"ğŸ’¾ Dosya boyutu tasarrufu: {size_reduction:.1f} MB ({size_reduction_pct:.1f}%)")
            print()
            
            # Kalite kontrolÃ¼
            print("ğŸ” QUALITY CHECK")
            print("-" * 15)
            
            # Null oranlarÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±
            original_null_pct = (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
            cleaned_null_pct = (df_cleaned.isnull().sum().sum() / (len(df_cleaned) * len(df_cleaned.columns))) * 100
            
            print(f"ğŸ“Š Null oranÄ±: %{original_null_pct:.1f} â†’ %{cleaned_null_pct:.1f}")
            print(f"ğŸ¯ Data quality: {'âœ… Ä°yileÅŸti' if cleaned_null_pct < original_null_pct else 'â– AynÄ±'}")
            
            # Veri tipi optimizasyonu kontrolÃ¼
            numeric_cols = len(df_cleaned.select_dtypes(include=[np.number]).columns)
            bool_cols = len(df_cleaned.select_dtypes(include=['bool', 'boolean']).columns)
            optimized_cols = numeric_cols + bool_cols
            optimization_pct = (optimized_cols / len(df_cleaned.columns)) * 100
            
            print(f"âš™ï¸ Optimized columns: {optimized_cols}/{len(df_cleaned.columns)} ({optimization_pct:.1f}%)")
            print()
            
            # Cumulative optimization summary
            print("ğŸ“Š CUMULATIVE OPTIMIZATION SUMMARY")
            print("-" * 35)
            original_dataset_size = 94  # BaÅŸlangÄ±Ã§ sÃ¼tun sayÄ±sÄ±
            total_deleted = original_dataset_size - final_cols
            
            print(f"ğŸ”» Toplam silinen sÃ¼tun: {total_deleted}")
            print(f"ğŸ“ˆ Dataset optimization: {original_dataset_size} â†’ {final_cols}")
            print(f"ğŸ¯ Optimization ratio: {(total_deleted/original_dataset_size)*100:.1f}%")
            print()
            
            # SonuÃ§ Ã¶zeti
            print("ğŸ† OPERATION SUMMARY")
            print("-" * 20)
            print("âœ… Ä°ÅŸlem baÅŸarÄ±yla tamamlandÄ±!")
            print(f"ğŸ—‘ï¸ Silinen sÃ¼tun: {column_to_delete}")
            print(f"ğŸ“Š Dataset durumu: {final_cols} sÃ¼tun, {memory_saved:.1f} MB tasarruf")
            print(f"ğŸ’¾ Yeni dosya: {output_filename}")
            print()
            print("ğŸš€ NEXT STEPS:")
            print("   1. 46_ teknik raporu hazÄ±rlanacak")
            print("   2. DiÄŸer optimization candidates analiz edilecek") 
            print("   3. Dataset quality monitoring devam edecek")
            
            return df_cleaned, {
                'deleted_column': column_to_delete,
                'memory_saved': memory_saved,
                'file_size_reduction': size_reduction,
                'null_improvement': original_null_pct - cleaned_null_pct,
                'final_columns': final_cols
            }
            
        else:
            print(f"âŒ SÃ¼tun bulunamadÄ±: {column_to_delete}")
            return df, {}
            
    except Exception as e:
        print(f"âŒ HATA: {str(e)}")
        return None, {}

if __name__ == "__main__":
    cleaned_df, stats = delete_predash_following_info_urn()
    
    if cleaned_df is not None and stats:
        print(f"\nğŸ¯ Ä°ÅŸlem tamamlandÄ±! Optimized dataset: {len(cleaned_df)} satÄ±r Ã— {len(cleaned_df.columns)} sÃ¼tun")
        print(f"ğŸ’¾ Memory tasarrufu: {stats['memory_saved']:.2f} MB")
    else:
        print("\nâŒ Ä°ÅŸlem baÅŸarÄ±sÄ±z!") 