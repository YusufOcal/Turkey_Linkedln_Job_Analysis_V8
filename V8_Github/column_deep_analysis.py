#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LinkedIn Jobs Dataset - Column Deep Analysis
merged_companyDescription ve company/followingState/followingType sÃ¼tunlarÄ±nÄ±n detaylÄ± analizi
"""

import pandas as pd
import numpy as np
from collections import Counter
import re
import warnings
warnings.filterwarnings('ignore')

def analyze_column_deep(df, column_name):
    """Belirli bir sÃ¼tun iÃ§in kapsamlÄ± analiz yapar"""
    
    print(f"ğŸ” DETAYLI ANALIZ: {column_name}")
    print("=" * 80)
    
    if column_name not in df.columns:
        print(f"âŒ HATA: '{column_name}' sÃ¼tunu bulunamadÄ±!")
        return None
    
    col_data = df[column_name]
    
    # 1. SÃœTUN TEMSÄ°LÄ° - Ne temsil ediyor?
    print("ğŸ“‹ 1. SÃœTUN TEMSÄ°LÄ° VE ANLAMI")
    print("-" * 40)
    
    if 'companyDescription' in column_name:
        print("ğŸ¢ Bu sÃ¼tun: Åirket aÃ§Ä±klamalarÄ±nÄ± (descriptions) temsil eder")
        print("   ğŸ“ Ä°Ã§erik: Åirketlerin kendilerini tanÄ±ttÄ±ÄŸÄ± metin bilgileri")
        print("   ğŸ¯ Business Value: Åirket profili analizi, sector classification")
        print("   ğŸ“Š Expected Type: Text/String (object)")
    
    elif 'followingType' in column_name:
        print("ğŸ‘¥ Bu sÃ¼tun: LinkedIn'de takip tÃ¼rÃ¼ kategorisini temsil eder")
        print("   ğŸ“ Ä°Ã§erik: KullanÄ±cÄ±larÄ±n ÅŸirketi nasÄ±l takip ettiÄŸi (PERSON, COMPANY, vb.)")
        print("   ğŸ¯ Business Value: User engagement analysis, following behavior")
        print("   ğŸ“Š Expected Type: Categorical (object veya category)")
    
    print()
    
    # 2. TEMEL Ä°STATÄ°STÄ°KLER
    print("ğŸ“Š 2. TEMEL Ä°STATÄ°STÄ°KLER")
    print("-" * 30)
    total_rows = len(col_data)
    null_count = col_data.isnull().sum()
    non_null_count = total_rows - null_count
    null_percentage = (null_count / total_rows) * 100
    
    print(f"ğŸ“‹ Toplam kayÄ±t: {total_rows:,}")
    print(f"âŒ Null deÄŸer: {null_count:,} ({null_percentage:.1f}%)")
    print(f"âœ… Dolu deÄŸer: {non_null_count:,} ({100-null_percentage:.1f}%)")
    print(f"ğŸ”§ Mevcut veri tipi: {col_data.dtype}")
    print()
    
    # 3. VERÄ° TÄ°PÄ° UYGUNLUÄU KONTROLÃœ
    print("âš™ï¸ 3. VERÄ° TÄ°PÄ° UYGUNLUÄU")
    print("-" * 25)
    
    non_null_data = col_data.dropna()
    if len(non_null_data) > 0:
        # String kontrolÃ¼
        all_strings = all(isinstance(val, str) for val in non_null_data)
        has_numbers = any(str(val).isdigit() for val in non_null_data)
        has_mixed = any(bool(re.search(r'\d', str(val))) and bool(re.search(r'[a-zA-Z]', str(val))) 
                       for val in non_null_data)
        
        print(f"ğŸ“ TÃ¼m deÄŸerler string: {'âœ… Evet' if all_strings else 'âŒ HayÄ±r'}")
        print(f"ğŸ”¢ SayÄ± iÃ§eren deÄŸerler: {'âš ï¸ Var' if has_numbers else 'âœ… Yok'}")
        print(f"ğŸ”¤ KarÄ±ÅŸÄ±k iÃ§erik: {'âš ï¸ Var' if has_mixed else 'âœ… Yok'}")
        
        # Ã–nerilen veri tipi
        if 'followingType' in column_name:
            unique_count = len(non_null_data.unique())
            if unique_count < 20:
                print(f"ğŸ’¡ Ã–NERÄ°: 'category' tipine Ã§evrilebilir ({unique_count} benzersiz deÄŸer)")
            else:
                print(f"ğŸ’¡ Ã–NERÄ°: 'object' tipi uygun ({unique_count} benzersiz deÄŸer)")
        else:
            print("ğŸ’¡ Ã–NERÄ°: 'object' tipi uygun (text content)")
    print()
    
    # 4. Ä°Ã‡ERÄ°K ANALÄ°ZÄ° VE TUTARSIZLIK TESPÄ°TÄ°
    print("ğŸ” 4. Ä°Ã‡ERÄ°K ANALÄ°ZÄ° VE TUTARLILIK")
    print("-" * 35)
    
    if len(non_null_data) > 0:
        # Benzersiz deÄŸer analizi
        unique_values = non_null_data.unique()
        unique_count = len(unique_values)
        value_counts = non_null_data.value_counts()
        
        print(f"ğŸ¯ Benzersiz deÄŸer sayÄ±sÄ±: {unique_count:,}")
        print(f"ğŸ“Š En sÄ±k deÄŸer: '{value_counts.index[0]}' ({value_counts.iloc[0]:,} kez)")
        
        if unique_count <= 20:
            print("\nğŸ“‹ TÃ¼m benzersiz deÄŸerler:")
            for i, (value, count) in enumerate(value_counts.items(), 1):
                percentage = (count / len(non_null_data)) * 100
                print(f"   {i:2d}. '{value}' â†’ {count:,} ({percentage:.1f}%)")
        else:
            print(f"\nğŸ“‹ En sÄ±k 10 deÄŸer:")
            for i, (value, count) in enumerate(value_counts.head(10).items(), 1):
                percentage = (count / len(non_null_data)) * 100
                # Uzun metinleri kÄ±salt
                display_value = value[:50] + "..." if len(str(value)) > 50 else value
                print(f"   {i:2d}. '{display_value}' â†’ {count:,} ({percentage:.1f}%)")
        
        # Uzunluk analizi (text iÃ§in)
        if col_data.dtype == 'object':
            lengths = non_null_data.astype(str).str.len()
            print(f"\nğŸ“ Karakter uzunluÄŸu analizi:")
            print(f"   Min: {lengths.min()} | Max: {lengths.max()}")
            print(f"   Ortalama: {lengths.mean():.1f} | Medyan: {lengths.median():.1f}")
            
            # Ã‡ok kÄ±sa veya Ã§ok uzun deÄŸerleri tespit et
            very_short = (lengths <= 2).sum()
            very_long = (lengths >= 1000).sum()
            if very_short > 0:
                print(f"   âš ï¸ Ã‡ok kÄ±sa deÄŸerler (â‰¤2 karakter): {very_short}")
            if very_long > 0:
                print(f"   âš ï¸ Ã‡ok uzun deÄŸerler (â‰¥1000 karakter): {very_long}")
    print()
    
    # 5. FORMAT TUTARSIZLIKLARI
    print("ğŸ”§ 5. FORMAT TUTARSIZLIKLARI")
    print("-" * 25)
    
    if len(non_null_data) > 0:
        # BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf farklÄ±lÄ±klarÄ±
        case_issues = {}
        normalized_values = non_null_data.str.lower()
        original_unique = len(non_null_data.unique())
        normalized_unique = len(normalized_values.unique())
        
        if original_unique != normalized_unique:
            case_difference = original_unique - normalized_unique
            print(f"âš ï¸ BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf farklÄ±lÄ±klarÄ±: {case_difference} potansiyel duplike")
            
            # Case-insensitive duplicates bul
            case_groups = non_null_data.groupby(non_null_data.str.lower()).apply(list)
            duplicates = case_groups[case_groups.str.len() > 1]
            
            if len(duplicates) > 0:
                print("   ğŸ“‹ Tespit edilen farklÄ±lÄ±klar:")
                for i, (normalized, variants) in enumerate(duplicates.head(5).items(), 1):
                    print(f"      {i}. '{normalized}' â†’ {variants}")
        else:
            print("âœ… BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf tutarsÄ±zlÄ±ÄŸÄ± bulunamadÄ±")
        
        # Ã–zel karakter kontrolÃ¼
        special_chars = non_null_data.str.contains(r'[^\w\s\-\.\,\(\)]', regex=True, na=False).sum()
        if special_chars > 0:
            print(f"âš ï¸ Ã–zel karakter iÃ§eren deÄŸerler: {special_chars}")
        else:
            print("âœ… Ã–zel karakter sorunu bulunamadÄ±")
        
        # TÃ¼rkÃ§e karakter kontrolÃ¼
        turkish_chars = non_null_data.str.contains(r'[Ã§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄIÃ–ÅÃœ]', regex=True, na=False).sum()
        english_equivalent = non_null_data.str.contains(r'[cgiosÃ¼CGIOSU]', regex=True, na=False).sum()
        
        if turkish_chars > 0 and english_equivalent > 0:
            print(f"âš ï¸ TÃ¼rkÃ§e/Ä°ngilizce karakter karÄ±ÅŸÄ±mÄ± olabilir")
            print(f"   TÃ¼rkÃ§e karakter iÃ§eren: {turkish_chars}")
    print()
    
    # 6. DÄ°ÄER SÃœTUNLARLA Ä°LÄ°ÅKÄ° ANALÄ°ZÄ°
    print("ğŸ”— 6. DÄ°ÄER SÃœTUNLARLA Ä°LÄ°ÅKÄ°")
    print("-" * 30)
    
    # Benzer isimli sÃ¼tunlarÄ± bul
    similar_columns = []
    col_base = column_name.lower().replace('/', '_').split('_')
    
    for other_col in df.columns:
        if other_col != column_name:
            other_base = other_col.lower().replace('/', '_').split('_')
            # Ortak kelime sayÄ±sÄ±
            common_words = set(col_base) & set(other_base)
            if len(common_words) > 0:
                similarity_score = len(common_words) / max(len(col_base), len(other_base))
                if similarity_score > 0.3:
                    similar_columns.append((other_col, similarity_score))
    
    if similar_columns:
        print("ğŸ” Benzer isimli sÃ¼tunlar bulundu:")
        for similar_col, score in sorted(similar_columns, key=lambda x: x[1], reverse=True)[:5]:
            print(f"   ğŸ“Š {similar_col} (benzerlik: {score:.2f})")
            
            # Ä°Ã§erik benzerliÄŸi kontrolÃ¼
            if similar_col in df.columns:
                try:
                    other_data = df[similar_col].dropna()
                    if len(other_data) > 0 and len(non_null_data) > 0:
                        # Ortak deÄŸer analizi
                        common_values = set(non_null_data.astype(str)) & set(other_data.astype(str))
                        if len(common_values) > 0:
                            overlap_pct = len(common_values) / max(len(set(non_null_data.astype(str))), len(set(other_data.astype(str)))) * 100
                            print(f"      ğŸ”— Ä°Ã§erik Ã¶rtÃ¼ÅŸmesi: {overlap_pct:.1f}% ({len(common_values)} ortak deÄŸer)")
                except:
                    pass
    else:
        print("âœ… Benzer isimli sÃ¼tun bulunamadÄ±")
    print()
    
    # 7. Ã–NERÄ°LER VE EYLEMLERÄ°
    print("ğŸ’¡ 7. Ã–NERÄ°LER VE EYLEM PLANI")
    print("-" * 30)
    
    recommendations = []
    
    # Null deÄŸer Ã¶nerileri
    if null_percentage > 50:
        recommendations.append(f"ğŸš¨ Ã‡OK YÃœKSEK NULL (%{null_percentage:.1f}) - SÃ¼tun silinmeyi dÃ¼ÅŸÃ¼nÃ¼lebilir")
    elif null_percentage > 20:
        recommendations.append(f"âš ï¸ YÃ¼ksek null (%{null_percentage:.1f}) - Doldurma stratejisi gerekli")
        
        if 'companyDescription' in column_name:
            recommendations.append("   â†’ 'AÃ§Ä±klama mevcut deÄŸil' veya benzer ÅŸirketlerden tahmin")
        elif 'followingType' in column_name:
            recommendations.append("   â†’ Dominant kategori ile doldur veya 'Unknown' kategorisi")
    
    # Veri tipi Ã¶nerileri
    if 'followingType' in column_name and len(non_null_data.unique()) < 10:
        recommendations.append("ğŸ”§ 'category' veri tipine Ã§evir (memory optimization)")
    
    # Format standardizasyonu
    if original_unique != normalized_unique:
        recommendations.append("ğŸ”¤ BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf standardizasyonu yap")
    
    # TutarsÄ±zlÄ±k Ã§Ã¶zÃ¼mleri
    if turkish_chars > 0 and english_equivalent > 0:
        recommendations.append("ğŸŒ TÃ¼rkÃ§e karakter standardizasyonu (Ä±â†’i, ÅŸâ†’s, vb.)")
    
    # Benzerlik Ã¶nerileri
    if similar_columns:
        for similar_col, score in similar_columns:
            if score > 0.8:
                recommendations.append(f"ğŸ”„ '{similar_col}' ile birleÅŸtirmeyi deÄŸerlendir (benzerlik: {score:.2f})")
    
    print("ğŸ“‹ Ã–nerilen Eylemler:")
    if recommendations:
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. {rec}")
    else:
        print("   âœ… SÃ¼tun genel olarak iyi durumda, major action gerekmiyor")
    
    print("\n" + "=" * 80)
    return {
        'column_name': column_name,
        'total_rows': total_rows,
        'null_count': null_count,
        'null_percentage': null_percentage,
        'unique_count': unique_count if len(non_null_data) > 0 else 0,
        'data_type': str(col_data.dtype),
        'recommendations': recommendations
    }

def main():
    """Ana analiz fonksiyonu"""
    
    print("ğŸ” LinkedIn Jobs Dataset - Column Deep Analysis")
    print("=" * 60)
    
    # Dataset'i yÃ¼kle
    try:
        df = pd.read_csv('linkedin_jobs_dataset_insights_completed.csv')
        print(f"âœ… Dataset yÃ¼klendi: {len(df):,} satÄ±r, {len(df.columns)} sÃ¼tun")
        print()
    except Exception as e:
        print(f"âŒ HATA: Dataset yÃ¼klenemedi - {e}")
        return
    
    # Analiz edilecek sÃ¼tunlar
    target_columns = [
        'merged_companyDescription',
        'company/followingState/followingType'
    ]
    
    results = {}
    
    for column in target_columns:
        result = analyze_column_deep(df, column)
        if result:
            results[column] = result
        print()
    
    # GENEL Ã–ZETÄ° VE SON Ã–NERÄ°LER
    print("ğŸ¯ GENEL Ã–ZET VE STRATEJÄ°K Ã–NERÄ°LER")
    print("=" * 50)
    
    for col_name, result in results.items():
        null_pct = result['null_percentage']
        unique_cnt = result['unique_count']
        
        print(f"\nğŸ“Š {col_name}:")
        print(f"   Null: %{null_pct:.1f} | Benzersiz: {unique_cnt:,}")
        
        if result['recommendations']:
            print("   ğŸ¯ Ã–ncelik eylemleri:")
            for rec in result['recommendations'][:3]:  # Ä°lk 3 Ã¶neri
                print(f"      â€¢ {rec}")
    
    print("\nğŸš€ SONRAKI ADIM: Hangi sÃ¼tundan baÅŸlamak istiyorsunuz?")

if __name__ == "__main__":
    main() 