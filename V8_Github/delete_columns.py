#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LinkedIn Jobs Dataset - Column Deletion Script
merged_companyDescription ve company/followingState/followingType sÃ¼tunlarÄ±nÄ± siler
"""

import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

def delete_problematic_columns():
    """Problematik sÃ¼tunlarÄ± siler ve sonuÃ§larÄ± raporlar"""
    
    print("ğŸ—‘ï¸ LinkedIn Jobs Dataset - Column Deletion Operation")
    print("=" * 60)
    
    try:
        # Dataset'i yÃ¼kle
        print("ğŸ“‚ Dataset yÃ¼kleniyor...")
        df = pd.read_csv('linkedin_jobs_dataset_insights_completed.csv')
        
        # Ä°lk durum
        initial_rows = len(df)
        initial_cols = len(df.columns)
        initial_memory = df.memory_usage(deep=True).sum() / 1024**2
        
        print(f"âœ… Dataset yÃ¼klendi!")
        print(f"ğŸ“Š Ä°lk durum: {initial_rows:,} satÄ±r Ã— {initial_cols} sÃ¼tun")
        print(f"ğŸ’¾ Ä°lk memory: {initial_memory:.2f} MB")
        print()
        
        # Silinecek sÃ¼tunlar
        columns_to_delete = [
            'merged_companyDescription',
            'company/followingState/followingType'
        ]
        
        print("ğŸ¯ DELETION ANALYSIS")
        print("-" * 25)
        
        total_memory_saved = 0
        deletion_report = []
        
        for col in columns_to_delete:
            if col in df.columns:
                # Bu sÃ¼tunun memory kullanÄ±mÄ±
                col_memory = df[col].memory_usage(deep=True) / 1024**2
                null_count = df[col].isnull().sum()
                null_pct = (null_count / len(df)) * 100
                unique_count = len(df[col].dropna().unique()) if df[col].notna().sum() > 0 else 0
                
                print(f"ğŸ” {col}:")
                print(f"   ğŸ“Š Null: {null_count:,} ({null_pct:.1f}%)")
                print(f"   ğŸ¯ Benzersiz deÄŸer: {unique_count:,}")
                print(f"   ğŸ’¾ Memory: {col_memory:.2f} MB")
                print(f"   âœ… SÄ°LÄ°NECEK!")
                
                deletion_report.append({
                    'column': col,
                    'memory_mb': col_memory,
                    'null_count': null_count,
                    'null_percentage': null_pct,
                    'unique_values': unique_count
                })
                
                total_memory_saved += col_memory
                print()
            else:
                print(f"âš ï¸ {col}: SÃ¼tun bulunamadÄ±!")
                print()
        
        # SÃ¼tunlarÄ± sil
        print("ğŸ—‘ï¸ DELETION PROCESS")
        print("-" * 20)
        
        existing_columns = [col for col in columns_to_delete if col in df.columns]
        
        if existing_columns:
            df_cleaned = df.drop(columns=existing_columns)
            
            # Son durum
            final_rows = len(df_cleaned)
            final_cols = len(df_cleaned.columns)
            final_memory = df_cleaned.memory_usage(deep=True).sum() / 1024**2
            
            # Ä°statistikler
            cols_deleted = len(existing_columns)
            memory_saved = initial_memory - final_memory
            memory_saved_pct = (memory_saved / initial_memory) * 100
            
            print(f"âœ… {cols_deleted} sÃ¼tun baÅŸarÄ±yla silindi!")
            print(f"ğŸ“Š Son durum: {final_rows:,} satÄ±r Ã— {final_cols} sÃ¼tun")
            print(f"ğŸ’¾ Son memory: {final_memory:.2f} MB")
            print()
            
            print("ğŸ“ˆ OPTIMIZATION RESULTS")
            print("-" * 25)
            print(f"ğŸ”» SÃ¼tun azalmasÄ±: {initial_cols} â†’ {final_cols} (-{cols_deleted})")
            print(f"ğŸ’¾ Memory tasarrufu: {memory_saved:.2f} MB ({memory_saved_pct:.1f}%)")
            print(f"ğŸ“Š SatÄ±r korunma: {final_rows:,} / {initial_rows:,} (100.0%)")
            print()
            
            # Silinen sÃ¼tunlarÄ±n detay raporu
            print("ğŸ“‹ DELETION SUMMARY")
            print("-" * 20)
            for i, report in enumerate(deletion_report, 1):
                print(f"{i}. {report['column']}:")
                print(f"   ğŸ“Š Null oranÄ±: %{report['null_percentage']:.1f}")
                print(f"   ğŸ¯ Benzersiz deÄŸer: {report['unique_values']:,}")
                print(f"   ğŸ’¾ Memory kurtarÄ±lan: {report['memory_mb']:.2f} MB")
                
                # Silme gerekÃ§esi
                if report['null_percentage'] > 50:
                    reason = "ğŸš¨ Ã‡ok yÃ¼ksek null oranÄ±"
                elif report['unique_values'] <= 1:
                    reason = "ğŸ”´ Zero/minimal variance"
                else:
                    reason = "âš ï¸ Low business value"
                print(f"   ğŸ’¡ GerekÃ§e: {reason}")
                print()
            
            # Yeni dosyayÄ± kaydet
            print("ğŸ’¾ SAVING CLEANED DATASET")
            print("-" * 25)
            
            output_filename = 'linkedin_jobs_dataset_cleaned_columns.csv'
            df_cleaned.to_csv(output_filename, index=False)
            
            # Dosya boyutu kontrolÃ¼
            file_size = Path(output_filename).stat().st_size / 1024**2
            original_size = Path('linkedin_jobs_dataset_insights_completed.csv').stat().st_size / 1024**2
            size_reduction = original_size - file_size
            size_reduction_pct = (size_reduction / original_size) * 100
            
            print(f"âœ… TemizlenmiÅŸ dataset kaydedildi: {output_filename}")
            print(f"ğŸ“„ Dosya boyutu: {file_size:.1f} MB (Ã¶nceki: {original_size:.1f} MB)")
            print(f"ğŸ’¾ Dosya boyutu tasarrufu: {size_reduction:.1f} MB ({size_reduction_pct:.1f}%)")
            print()
            
            # Kalite kontrolÃ¼
            print("ğŸ” QUALITY CHECK")
            print("-" * 15)
            
            # Null oranlarÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±
            original_null_pct = (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
            cleaned_null_pct = (df_cleaned.isnull().sum().sum() / (len(df_cleaned) * len(df_cleaned.columns))) * 100
            
            print(f"ğŸ“Š Null oranÄ±: %{original_null_pct:.1f} â†’ %{cleaned_null_pct:.1f}")
            print(f"ğŸ¯ Data quality improvement: {'âœ… Ä°yileÅŸti' if cleaned_null_pct < original_null_pct else 'â– AynÄ±'}")
            
            # Veri tipi optimizasyonu kontrolÃ¼
            numeric_cols = len(df_cleaned.select_dtypes(include=[np.number]).columns)
            bool_cols = len(df_cleaned.select_dtypes(include=['bool', 'boolean']).columns)
            optimized_cols = numeric_cols + bool_cols
            optimization_pct = (optimized_cols / len(df_cleaned.columns)) * 100
            
            print(f"âš™ï¸ Optimized columns: {optimized_cols}/{len(df_cleaned.columns)} ({optimization_pct:.1f}%)")
            print()
            
            # SonuÃ§ Ã¶zeti
            print("ğŸ† OPERATION SUMMARY")
            print("-" * 20)
            print("âœ… Ä°ÅŸlemler baÅŸarÄ±yla tamamlandÄ±!")
            print(f"ğŸ—‘ï¸ Silinen sÃ¼tunlar: {', '.join(existing_columns)}")
            print(f"ğŸ“Š Dataset optimizasyonu: {cols_deleted} sÃ¼tun, {memory_saved:.1f} MB tasarruf")
            print(f"ğŸ’¾ Yeni dosya: {output_filename}")
            print()
            print("ğŸš€ NEXT STEPS:")
            print("   1. Yeni dataset'i inceleyin")
            print("   2. DiÄŸer problematik sÃ¼tunlarÄ± tespit edin") 
            print("   3. Veri kalitesi optimizasyonuna devam edin")
            
            return df_cleaned, deletion_report
            
        else:
            print("âŒ Silinecek sÃ¼tun bulunamadÄ±!")
            return df, []
            
    except Exception as e:
        print(f"âŒ HATA: {str(e)}")
        return None, []

if __name__ == "__main__":
    cleaned_df, report = delete_problematic_columns()
    
    if cleaned_df is not None:
        print(f"\nğŸ¯ Ä°ÅŸlem tamamlandÄ±! Yeni dataset: {len(cleaned_df)} satÄ±r Ã— {len(cleaned_df.columns)} sÃ¼tun")
    else:
        print("\nâŒ Ä°ÅŸlem baÅŸarÄ±sÄ±z!") 