#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LinkedIn Jobs Dataset - Job Investment Category Creation & ContentSource Deletion
ContentSource sÃ¼tunundan business-friendly kategori oluÅŸturup orijinal sÃ¼tunu silen script yazÄ±yorum.
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

def create_job_investment_category_and_delete_source(df):
    """ContentSource'dan yeni kategori oluÅŸtur ve orijinal sÃ¼tunu sil"""
    
    print("ğŸ—ï¸ JOB INVESTMENT CATEGORY CREATION & CONTENTSOURCE DELETION")
    print("=" * 65)
    
    source_column = 'contentSource'
    new_column = 'job_investment_type'
    
    # Check if source column exists
    if source_column not in df.columns:
        print(f"âŒ HATA: {source_column} sÃ¼tunu bulunamadÄ±!")
        return None
    
    # 1. ORIGINAL DATA ANALYSIS
    print("ğŸ“Š 1. ORÄ°JÄ°NAL VERÄ° ANALÄ°ZÄ°")
    print("-" * 30)
    
    original_stats = df[source_column].value_counts()
    print("ğŸ“‹ Mevcut ContentSource DaÄŸÄ±lÄ±mÄ±:")
    for value, count in original_stats.items():
        percentage = (count / len(df)) * 100
        print(f"   ğŸ“Š {value}: {count:,} ilan ({percentage:.1f}%)")
    print()
    
    # 2. NEW CATEGORY MAPPING STRATEGY
    print("ğŸ¯ 2. YENÄ° KATEGORÄ° MAPPING STRATEJÄ°SÄ°")
    print("-" * 40)
    
    print("ğŸ’¡ Business-Friendly Kategori Mapping:")
    
    category_mapping = {
        'JOBS_PREMIUM_OFFLINE': 'PREMIUM_OFFLINE',
        'JOBS_PREMIUM': 'PREMIUM_ONLINE', 
        'JOBS_CREATE': 'ORGANIC'
    }
    
    business_explanations = {
        'PREMIUM_OFFLINE': {
            'meaning': 'Ãœcretli Ä°lan (Offline Ä°ÅŸlenmiÅŸ)',
            'description': 'Åirketlerin LinkedIn\'e para Ã¶dediÄŸi, toplu iÅŸlenmiÅŸ premium ilanlar',
            'investment': 'PAID - Company Investment',
            'quality': 'HIGH - Premium features',
            'visibility': 'High visibility, priority listing'
        },
        'PREMIUM_ONLINE': {
            'meaning': 'Ãœcretli Ä°lan (Online Ä°ÅŸlenmiÅŸ)',
            'description': 'Åirketlerin LinkedIn\'e para Ã¶dediÄŸi, gerÃ§ek zamanlÄ± premium ilanlar',
            'investment': 'PAID - Company Investment',
            'quality': 'HIGH - Premium features + Real-time',
            'visibility': 'High visibility, immediate processing'
        },
        'ORGANIC': {
            'meaning': 'Ãœcretsiz/Organik Ä°lan',
            'description': 'Åirketlerin Ã¼cretsiz olarak oluÅŸturduÄŸu temel seviye ilanlar',
            'investment': 'FREE - No cost to company',
            'quality': 'STANDARD - Basic features',
            'visibility': 'Standard visibility'
        }
    }
    
    for old_value, new_value in category_mapping.items():
        old_count = original_stats.get(old_value, 0)
        old_percentage = (old_count / len(df)) * 100 if old_count > 0 else 0
        explanation = business_explanations[new_value]
        
        print(f"ğŸ”„ {old_value} â†’ {new_value}")
        print(f"   ğŸ“Š Count: {old_count:,} ilan ({old_percentage:.1f}%)")
        print(f"   ğŸ“ Meaning: {explanation['meaning']}")
        print(f"   ğŸ’¼ Description: {explanation['description']}")
        print(f"   ğŸ’° Investment: {explanation['investment']}")
        print(f"   ğŸ¯ Quality: {explanation['quality']}")
        print(f"   ğŸ‘ï¸ Visibility: {explanation['visibility']}")
        print()
    
    # 3. CREATE NEW COLUMN
    print("ğŸ—ï¸ 3. YENÄ° SÃœTUN OLUÅTURMA")
    print("-" * 25)
    
    print(f"ğŸ“ Yeni sÃ¼tun oluÅŸturuluyor: {new_column}")
    
    # Apply mapping
    df[new_column] = df[source_column].map(category_mapping)
    
    # Verify mapping success
    unmapped_count = df[new_column].isnull().sum()
    if unmapped_count > 0:
        print(f"âš ï¸ UYARI: {unmapped_count} deÄŸer map edilemedi!")
        unmapped_values = df[df[new_column].isnull()][source_column].unique()
        print(f"ğŸ“‹ Map edilemeyen deÄŸerler: {unmapped_values}")
    else:
        print("âœ… TÃ¼m deÄŸerler baÅŸarÄ±yla map edildi!")
    
    # Convert to category type for memory optimization
    df[new_column] = df[new_column].astype('category')
    
    print(f"âœ… Yeni sÃ¼tun oluÅŸturuldu ve 'category' tipine Ã§evrildi")
    print()
    
    # 4. NEW COLUMN VERIFICATION
    print("ğŸ” 4. YENÄ° SÃœTUN VERÄ°FÄ°KASYONU")
    print("-" * 30)
    
    new_stats = df[new_column].value_counts()
    new_memory = df[new_column].memory_usage(deep=True) / 1024**2
    
    print("ğŸ“Š Yeni Job Investment Type DaÄŸÄ±lÄ±mÄ±:")
    for value, count in new_stats.items():
        percentage = (count / len(df)) * 100
        print(f"   ğŸ“Š {value}: {count:,} ilan ({percentage:.1f}%)")
    
    print(f"\nğŸ“ˆ Yeni sÃ¼tun Ã¶zellikleri:")
    print(f"   ğŸ”§ Data Type: {df[new_column].dtype}")
    print(f"   ğŸ¯ Unique Values: {df[new_column].nunique()}")
    print(f"   ğŸ’¾ Memory Usage: {new_memory:.3f} MB")
    print()
    
    # 5. MEMORY COMPARISON BEFORE DELETION
    print("ğŸ“Š 5. MEMORY COMPARISON (DELETE Ã–NCESÄ°)")
    print("-" * 40)
    
    original_memory = df[source_column].memory_usage(deep=True) / 1024**2
    
    print(f"ğŸ“‹ Memory KarÅŸÄ±laÅŸtÄ±rmasÄ±:")
    print(f"   ğŸ“Š Original ({source_column}): {original_memory:.3f} MB (object)")
    print(f"   ğŸ“Š New ({new_column}): {new_memory:.3f} MB (category)")
    print(f"   ğŸ’¾ Memory Difference: {original_memory - new_memory:.3f} MB")
    print(f"   ğŸ“ˆ Memory Efficiency: {((original_memory - new_memory) / original_memory * 100):.1f}% improvement")
    print()
    
    # 6. SAFE DELETION PROTOCOL
    print("ğŸ—‘ï¸ 6. SAFE DELETION PROTOCOL")
    print("-" * 30)
    
    print("ğŸ“‹ Deletion Safety Checklist:")
    
    # Verify data integrity
    data_integrity_check = len(new_stats) == len(original_stats)
    print(f"   âœ… Category count preserved: {data_integrity_check}")
    
    # Verify no data loss
    original_total = original_stats.sum()
    new_total = new_stats.sum()
    data_loss_check = original_total == new_total
    print(f"   âœ… No data loss: {data_loss_check} ({original_total} â†’ {new_total})")
    
    # Verify business logic preserved
    premium_offline_preserved = new_stats.get('PREMIUM_OFFLINE', 0) == original_stats.get('JOBS_PREMIUM_OFFLINE', 0)
    premium_online_preserved = new_stats.get('PREMIUM_ONLINE', 0) == original_stats.get('JOBS_PREMIUM', 0)
    organic_preserved = new_stats.get('ORGANIC', 0) == original_stats.get('JOBS_CREATE', 0)
    
    business_logic_check = premium_offline_preserved and premium_online_preserved and organic_preserved
    print(f"   âœ… Business logic preserved: {business_logic_check}")
    
    # Overall safety assessment
    safe_to_delete = data_integrity_check and data_loss_check and business_logic_check
    print(f"   ğŸ¯ Safe to delete: {safe_to_delete}")
    print()
    
    if safe_to_delete:
        print("ğŸ—‘ï¸ DELETING ORIGINAL COLUMN...")
        
        # Get baseline metrics before deletion
        columns_before = len(df.columns)
        memory_before = df.memory_usage(deep=True).sum() / 1024**2
        
        # Delete original column
        df.drop(columns=[source_column], inplace=True)
        
        # Get metrics after deletion
        columns_after = len(df.columns)
        memory_after = df.memory_usage(deep=True).sum() / 1024**2
        
        print("âœ… Original contentSource column deleted successfully!")
        print()
        
        # 7. DELETION RESULTS
        print("ğŸ“ˆ 7. DELETION RESULTS")
        print("-" * 20)
        
        column_reduction = columns_before - columns_after
        memory_saved = memory_before - memory_after
        memory_saved_percentage = (memory_saved / memory_before) * 100
        
        print(f"ğŸ“Š Schema Changes:")
        print(f"   ğŸ“‹ Columns Before: {columns_before}")
        print(f"   ğŸ“‹ Columns After: {columns_after}")
        print(f"   ğŸ“‰ Column Reduction: {column_reduction}")
        
        print(f"\nğŸ’¾ Memory Optimization:")
        print(f"   ğŸ“Š Memory Before: {memory_before:.2f} MB")
        print(f"   ğŸ“Š Memory After: {memory_after:.2f} MB")
        print(f"   ğŸ“‰ Memory Saved: {memory_saved:.3f} MB")
        print(f"   ğŸ“ˆ Memory Improvement: {memory_saved_percentage:.2f}%")
        print()
        
        # 8. FINAL BUSINESS VALUE ASSESSMENT
        print("ğŸ¯ 8. FINAL BUSINESS VALUE ASSESSMENT")
        print("-" * 35)
        
        print("âœ… ACHIEVED IMPROVEMENTS:")
        print(f"   ğŸ—ï¸ Business-Friendly Categories: Technical â†’ Business terms")
        print(f"   ğŸ’¾ Memory Optimization: {memory_saved:.3f} MB saved")
        print(f"   ğŸ”§ Data Type Optimization: object â†’ category")
        print(f"   ğŸ“Š Enhanced Analytics: Clear investment classification")
        print(f"   ğŸ¯ Improved Usability: Intuitive category names")
        
        print(f"\nğŸ“ˆ NEW COLUMN ADVANTAGES:")
        print(f"   ğŸ’° PREMIUM_OFFLINE: Clear paid content identification")
        print(f"   âš¡ PREMIUM_ONLINE: Real-time paid content distinction")
        print(f"   ğŸŒ± ORGANIC: Free content clear classification")
        print(f"   ğŸ“Š Analytics Ready: Perfect for business analysis")
        
        return {
            'success': True,
            'new_column': new_column,
            'deleted_column': source_column,
            'columns_before': columns_before,
            'columns_after': columns_after,
            'memory_saved_mb': memory_saved,
            'memory_improvement_pct': memory_saved_percentage,
            'category_distribution': dict(new_stats),
            'business_categories': list(category_mapping.values())
        }
    else:
        print("âŒ SAFETY CHECK FAILED - Deletion aborted!")
        print("ğŸ” Please review data integrity issues before proceeding")
        return {
            'success': False,
            'reason': 'Safety check failed',
            'data_integrity_check': data_integrity_check,
            'data_loss_check': data_loss_check,
            'business_logic_check': business_logic_check
        }

if __name__ == "__main__":
    try:
        print("ğŸ“‚ Dataset yÃ¼kleniyor...")
        df = pd.read_csv('linkedin_jobs_dataset_optimized_step6.csv')
        print(f"âœ… Dataset yÃ¼klendi: {len(df):,} kayÄ±t, {len(df.columns)} sÃ¼tun")
        print()
        
        result = create_job_investment_category_and_delete_source(df)
        
        if result and result['success']:
            print("ğŸ‰ Ä°ÅLEM BAÅARILI!")
            print(f"âœ… Yeni sÃ¼tun '{result['new_column']}' oluÅŸturuldu")
            print(f"ğŸ—‘ï¸ Eski sÃ¼tun '{result['deleted_column']}' silindi") 
            print(f"ğŸ’¾ {result['memory_saved_mb']:.3f} MB memory tasarrufu saÄŸlandÄ±")
            
            # Save the updated dataset
            output_file = 'linkedin_jobs_dataset_optimized_step7.csv'
            df.to_csv(output_file, index=False)
            print(f"ğŸ’¾ GÃ¼ncellenmiÅŸ dataset kaydedildi: {output_file}")
        else:
            print("âŒ Ä°ÅŸlem baÅŸarÄ±sÄ±z!")
            
    except Exception as e:
        print(f"âŒ HATA: {str(e)}") 